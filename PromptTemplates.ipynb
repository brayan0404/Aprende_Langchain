{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8W0SMnzmr0Bq3GGQ78WNp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brayan0404/Aprende_Langchain/blob/main/PromptTemplates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBJETIVO**\n",
        "\n",
        "En este documento tengo como objetivo aprender lo basico de los promptTemplates. Que son, como funcionan y que solucionan.\n",
        "\n",
        "\n",
        "# **PRMPT-TEMPLATES**\n",
        "Los promptTemplates es la forma que tenemos en langchain de crear y configurar prompts. Pero que son exactamente las Prompts y las promptTeamplates. Bueno, las prompts son las entradas de texto que le ingresamos a los llms, es decir, las preguntas u indicaciones que hacemos a los llms, esas prompts pueden ser configuradas y optimizadas para tareas especificas, asi por ejemplo podemos querer crear un prompt que nos permita hacer resumenes con unas caractaeristicas que todos nuestros resumenes deben tener, y con ello lo que buscamos es que nuestro output sea repetitivo y predecible para nosotros, he aqui donde entran en juego los PromptTemplates, estas erramientas te permiten crear estructuralmente esas prompts para que tu como usuario no tengas que repetir una prompt una y otra vez, por ejemplo, \"Resume este texto que te paso a continuacion, cuyo nombre es tal, hazlo de esta forma, debe contener esto, no hagas esto, etc\", sino que solo le pasas las partes del texto que son modificables, o particulares para cada texto y asi te ahorras esta tarea repetiva, asi, \"Resume este texto que te paso a continuacion, cuyo nombre es [nombre_texto], hazlo de esta [estilo_escritura], debe contener [diez_hojas], no hagas esto, etc\".\n",
        "\n",
        "Acontinuacion cada linea del codigo es explicada en su funcionalidad."
      ],
      "metadata": {
        "id": "maFGmwkJuahx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEy1bUxHaluG"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sin langchain no hay promptTemplates asi que instalamos esta libreria"
      ],
      "metadata": {
        "id": "V4J_tWSDxZt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "-qtKoWy5a4PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langchain tiene un modulo en especifico dedicado a las prompts, entre los metodos de prompts tenemos uno en especifico para configurar promptTemplates, el cual tiene este mismo nombre, asi del modulo prompts traemos este metodo para configurar y crear nuestros prompts."
      ],
      "metadata": {
        "id": "BFXwOpEXxjEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"company_activity\"],\n",
        "    template=\"Cual es un buen nombre para una empresa que vende {company_activity}\",\n",
        "    )"
      ],
      "metadata": {
        "id": "P1_O2WIqa_kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta linea creamos una variable, en cuyo contenido usamos el metodo PromptTemplate, el cual, toma dos argumentos, el primero de ellos llamado input_variables, y el segundo template.\n",
        "\n",
        "**Input_variables**\n",
        "\n",
        "A esta variable debemos pasar la parte del texto o la parte variable de nuestro prompt, asi por ejemplo si tenemos un prompt donde le pedimos al llm que \"basado en lo que vende la empresa nos genere un nombre\", la parte variable es la actividad o lo que vende la empresa, y seria lo unico que tendriamos que ingresar asi, \"Basado en lo que vende la empresa, cual seria un buen nombre para una que vende [zapatos]\". Cabe destacar que esa actividad la vamos a pasar no en input_variables, sino en el campo de input del llm, asi las cosas solo debemos ingresar lo que d¿vende la empresa, y el modelo une todo el prompt y nos genera el resultado. Este punto sera mas claro cuando vea el codigo.\n",
        "\n",
        "**Temaplate**\n",
        "\n",
        "El parametro template recibe la parte inmobil o inmodificable del prompt, con el ejemplo anterior, la parte invariable es toda la que no está en parentesis."
      ],
      "metadata": {
        "id": "6pAAXWH2x81W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.format(company_activity=\"zapatos\")"
      ],
      "metadata": {
        "id": "qHnpQDZZbX9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta linea de codigo es la encargada de formatear el input_variable con el template, o en otras palabras de unirlos, y de esta forma ya esta listo ahora si para ingresar en el llm.\n",
        "\n",
        "Por ultimo, en este documento solo tenemos como fn crear el PromptTemplate para generar la prompt, mas no de pasar el texto al llm."
      ],
      "metadata": {
        "id": "HksoscP70lZQ"
      }
    }
  ]
}